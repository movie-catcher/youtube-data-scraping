{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.____ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw5Zz2NYEE-k"
      },
      "source": [
        "# ëŒ“ê¸€ ë°ì´í„° ê°ì„±ë¶„ì„\n",
        "- Aurora3 ê¸°ë°˜ https://github.com/gyubok-lee/Aurora3\n",
        "- Google colaboratory ì´ìš©ì‹œ drive mount & cd ì„¤ì • í•„ìš”\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJdmaAk1SqKz"
      },
      "source": [
        "\"\"\"\n",
        "cd /content/drive/MyDrive/ê²½ë¡œì„¤ì •\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFehu9X3RuLL"
      },
      "source": [
        "# konply ì„¤ì¹˜\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psetTOI5RuBj"
      },
      "source": [
        "# module & package ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import konlpy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager, rc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(-2, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQypLXv63Ef3"
      },
      "source": [
        "# ì‘ì—…ìˆœì„œ\n",
        "- input data íŒŒì¼ í˜•ì‹ ë°”ê¿”ì£¼ê¸°\n",
        "- test, train data ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "- ë°ì´í„° ì „ì²˜ë¦¬ ì‘ì—…\n",
        "- ë‹¨ì–´ë³„ë¡œ ê°ì„±ì ìˆ˜ ì¸¡ì •, ì¶”ì •\n",
        "- ëŒ“ê¸€ ë¬¸ì¥ ë³„ ê°ì„±ë¶„ì„\n",
        "- score ì¸¡ì  ê²°ê³¼ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJRGWz_RmZg"
      },
      "source": [
        "\"\"\"\n",
        "- íŒŒì¼ ë³€í™˜ -\n",
        "\n",
        "df = pd.read_excel('íŒŒì¼ê²½ë¡œ/ë³€í™˜ ì „ íŒŒì¼ì´ë¦„.xlsx')\n",
        "print(df)\n",
        "df.to_csv('ë³€í™˜ í›„ ìƒˆë¡œ ìƒê¸°ëŠ” íŒŒì¼ì´ë¦„.txt',index=True)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AMDzdUe7Y_j"
      },
      "source": [
        "# ì˜í™”ì œëª© ì ì–´ì£¼ê¸°\n",
        "\n",
        "movie_name = \"#ì‚´ì•„ìˆë‹¤\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kxlbrTkScLw",
        "outputId": "a332547f-4e2f-490f-cb61-9c7e79a27e6f"
      },
      "source": [
        "df = pd.read_excel(f'data_xlsx/youtube_comments_{movie_name}.xlsx')\n",
        "print(df)\n",
        "df.to_csv(f'data_txt/youtube_comments_{movie_name}.txt',index=True, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                comment  ...      videoId\n",
            "0                                          ê°“ì§íˆ ë¼ë©´ì€ ì§„ìˆœì´ì§€  ...  wm06nhjoAQ8\n",
            "1                                           ë‚˜ë§Œ ì¬ë°Œê²Œ ë´¤ë‚˜.?  ...  wm06nhjoAQ8\n",
            "2     í•˜..ë°˜ë„ë³´ê³ ë„ í—ˆë¬´í–ˆëŠ”ë°..ì´ê²ƒë„ ê·¸ëŸ°ê°€ìš”. <a href=\"http://www....  ...  wm06nhjoAQ8\n",
            "3       ê·¸ëŸ°ë° ì œê°€ë³´ê¸°ì—” ê´œì°®ì€ê²Œ ìƒì¡´ì˜ ìƒê°ì„ ëª»í•˜ê³  ì•ì—ë³´ì´ëŠ”ê±°ë§Œ ë³´ëŠ”ì´ë¯¸ì§€ ê´œì°®ì•˜ìŠµë‹ˆë‹¤  ...  wm06nhjoAQ8\n",
            "4                                               ã…ˆã„´ë¶ˆí¸í•˜ë„¹?  ...  wm06nhjoAQ8\n",
            "...                                                 ...  ...          ...\n",
            "4840                                    ë‚˜ë§Œ ì´ë…¸ë˜ê°€ ã…—ë¦„ ë¼ì¹œê°€?  ...  YzS9h3T2bXY\n",
            "4841  ì´ê±° ë“¤ìœ¼ë©´ì„œ í•™ì›ê°ˆ ì¤€ë¹„í•˜ë©´ ì™„ì „ ì¢€ë¹„ë‘ <br>ì‹¸ìš°ëŸ¬ ê°€ë ¤ê³  ì¤€ë¹„í•˜ëŠ” ê¸°ë¶„..<...  ...  YzS9h3T2bXY\n",
            "4842                                           ê³µë¶€ë‘ ì‹¸ìš°ë‹¤ë‹ˆ  ...  YzS9h3T2bXY\n",
            "4843                                               ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†  ...  YzS9h3T2bXY\n",
            "4844                                             ì¸ì •ìš”ã…‹ã…‹ã…‹  ...  YzS9h3T2bXY\n",
            "\n",
            "[4845 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "HYsUb96hScGX",
        "outputId": "aad8180d-cc2d-46da-f911-b33ee89ad4f5"
      },
      "source": [
        "# ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì€ ë‹¤ìŒê³¼ ê°™ì€ ì–‘ì‹ìœ¼ë¡œ í†µì¼í•  ê²ƒ\n",
        "df = pd.read_table(f'data_txt/youtube_comments_{movie_name}.txt')\n",
        "#ì˜í™”ë³„ë¡œ ì´ ëŒ“ê¸€ ìˆ˜ ë‹¤ë¦„ -> ìë™í™”\n",
        "df = df.iloc[:,:] \n",
        "# ê¸°ì¡´ row nameì„ dataì— ë§ê²Œ ë³€ê²½\n",
        "df = df[['videoId','comment']]\n",
        "df = df.rename(columns={\"videoId\": \"id\", \"comment\": \"sentence\"})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ê°“ì§íˆ ë¼ë©´ì€ ì§„ìˆœì´ì§€</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ë‚˜ë§Œ ì¬ë°Œê²Œ ë´¤ë‚˜.?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>í•˜..ë°˜ë„ë³´ê³ ë„ í—ˆë¬´í–ˆëŠ”ë°..ì´ê²ƒë„ ê·¸ëŸ°ê°€ìš”. &lt;a href=\"http://www....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ê·¸ëŸ°ë° ì œê°€ë³´ê¸°ì—” ê´œì°®ì€ê²Œ ìƒì¡´ì˜ ìƒê°ì„ ëª»í•˜ê³  ì•ì—ë³´ì´ëŠ”ê±°ë§Œ ë³´ëŠ”ì´ë¯¸ì§€ ê´œì°®ì•˜ìŠµë‹ˆë‹¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ã…ˆã„´ë¶ˆí¸í•˜ë„¹?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ë‚˜ë§Œ ì´ë…¸ë˜ê°€ ã…—ë¦„ ë¼ì¹œê°€?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ì´ê±° ë“¤ìœ¼ë©´ì„œ í•™ì›ê°ˆ ì¤€ë¹„í•˜ë©´ ì™„ì „ ì¢€ë¹„ë‘ &lt;br&gt;ì‹¸ìš°ëŸ¬ ê°€ë ¤ê³  ì¤€ë¹„í•˜ëŠ” ê¸°ë¶„..&lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ê³µë¶€ë‘ ì‹¸ìš°ë‹¤ë‹ˆ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ì¸ì •ìš”ã…‹ã…‹ã…‹</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4845 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id                                           sentence\n",
              "0     wm06nhjoAQ8                                       ê°“ì§íˆ ë¼ë©´ì€ ì§„ìˆœì´ì§€\n",
              "1     wm06nhjoAQ8                                        ë‚˜ë§Œ ì¬ë°Œê²Œ ë´¤ë‚˜.?\n",
              "2     wm06nhjoAQ8  í•˜..ë°˜ë„ë³´ê³ ë„ í—ˆë¬´í–ˆëŠ”ë°..ì´ê²ƒë„ ê·¸ëŸ°ê°€ìš”. <a href=\"http://www....\n",
              "3     wm06nhjoAQ8    ê·¸ëŸ°ë° ì œê°€ë³´ê¸°ì—” ê´œì°®ì€ê²Œ ìƒì¡´ì˜ ìƒê°ì„ ëª»í•˜ê³  ì•ì—ë³´ì´ëŠ”ê±°ë§Œ ë³´ëŠ”ì´ë¯¸ì§€ ê´œì°®ì•˜ìŠµë‹ˆë‹¤\n",
              "4     wm06nhjoAQ8                                            ã…ˆã„´ë¶ˆí¸í•˜ë„¹?\n",
              "...           ...                                                ...\n",
              "4840  YzS9h3T2bXY                                    ë‚˜ë§Œ ì´ë…¸ë˜ê°€ ã…—ë¦„ ë¼ì¹œê°€?\n",
              "4841  YzS9h3T2bXY  ì´ê±° ë“¤ìœ¼ë©´ì„œ í•™ì›ê°ˆ ì¤€ë¹„í•˜ë©´ ì™„ì „ ì¢€ë¹„ë‘ <br>ì‹¸ìš°ëŸ¬ ê°€ë ¤ê³  ì¤€ë¹„í•˜ëŠ” ê¸°ë¶„..<...\n",
              "4842  YzS9h3T2bXY                                           ê³µë¶€ë‘ ì‹¸ìš°ë‹¤ë‹ˆ\n",
              "4843  YzS9h3T2bXY                                               ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†\n",
              "4844  YzS9h3T2bXY                                             ì¸ì •ìš”ã…‹ã…‹ã…‹\n",
              "\n",
              "[4845 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BuewPYDEE_K"
      },
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬ ë° í† í°í™” ì‘ì—…\n",
        "\n",
        "okt = konlpy.tag.Okt()\n",
        "\n",
        "def text_preprocess(x):\n",
        "    text=[]\n",
        "    \"\"\"\n",
        "    <br>, <a href~ > ë“±ì˜ íƒœê·¸ ì œê±° ì‘ì—… ì¶”ê°€ í•„ìš”\n",
        "    \"\"\"\n",
        "    x = re.sub(\"<.+?>\",\"\",x)\n",
        "    a = re.sub('[^ê°€-í£0-9a-zA-Z\\\\s]', '',x)\n",
        "    for j in a.split():\n",
        "        text.append(j)\n",
        "    return ' '.join(text)\n",
        "\n",
        "def tokenize(x):\n",
        "    text = []\n",
        "    tokens = okt.pos(x)\n",
        "    for token in tokens :\n",
        "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
        "            text.append(token[0])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "1nVp8kPOJm1F",
        "outputId": "f0bc33e6-60e5-4db7-cbdd-cdd147049ec8"
      },
      "source": [
        "# ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "\n",
        "tqdm.pandas()\n",
        "df['comment_cut'] = df['sentence'].apply(lambda x : text_preprocess(x))\n",
        "df['comment_cut'] = df['comment_cut'].progress_apply(lambda x: tokenize(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4845/4845 [00:21<00:00, 227.86it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>comment_cut</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ê°“ì§íˆ ë¼ë©´ì€ ì§„ìˆœì´ì§€</td>\n",
              "      <td>[ê°“, ì§íˆ, ë¼ë©´, ì€, ì§„, ìˆœì´, ì§€]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ë‚˜ë§Œ ì¬ë°Œê²Œ ë´¤ë‚˜.?</td>\n",
              "      <td>[ë‚˜, ë§Œ, ì¬ë°Œê²Œ, ë´¤ë‚˜]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>í•˜..ë°˜ë„ë³´ê³ ë„ í—ˆë¬´í–ˆëŠ”ë°..ì´ê²ƒë„ ê·¸ëŸ°ê°€ìš”. &lt;a href=\"http://www....</td>\n",
              "      <td>[í•˜ë°˜, ë„ë³´, ê³ ë„, í—ˆë¬´í–ˆëŠ”ë°ì´ê²ƒë„, ê·¸ëŸ°, ê°€ìš”, ì‚´ì•„ë§Œ, ìˆë‹¤, ì¸ê°€ìš”, ì˜¤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ê·¸ëŸ°ë° ì œê°€ë³´ê¸°ì—” ê´œì°®ì€ê²Œ ìƒì¡´ì˜ ìƒê°ì„ ëª»í•˜ê³  ì•ì—ë³´ì´ëŠ”ê±°ë§Œ ë³´ëŠ”ì´ë¯¸ì§€ ê´œì°®ì•˜ìŠµë‹ˆë‹¤</td>\n",
              "      <td>[ê·¸ëŸ°ë°, ì œ, ê°€ë³´ê¸°ì—”, ê´œì°®, ì€, ê²Œ, ìƒì¡´, ì˜, ìƒê°, ì„, ëª», í•˜ê³ , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ã…ˆã„´ë¶ˆí¸í•˜ë„¹?</td>\n",
              "      <td>[ë¶ˆí¸í•˜, ë„¹]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ë‚˜ë§Œ ì´ë…¸ë˜ê°€ ã…—ë¦„ ë¼ì¹œê°€?</td>\n",
              "      <td>[ë‚˜, ë§Œ, ì´, ë…¸ë˜, ê°€, ë¦„, ë¼ì¹œê°€]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ì´ê±° ë“¤ìœ¼ë©´ì„œ í•™ì›ê°ˆ ì¤€ë¹„í•˜ë©´ ì™„ì „ ì¢€ë¹„ë‘ &lt;br&gt;ì‹¸ìš°ëŸ¬ ê°€ë ¤ê³  ì¤€ë¹„í•˜ëŠ” ê¸°ë¶„..&lt;...</td>\n",
              "      <td>[ì´, ê±°, ë“¤ìœ¼ë©´ì„œ, í•™ì›, ê°ˆ, ì¤€ë¹„, í•˜ë©´, ì™„ì „, ì¢€ë¹„, ë‘, ì‹¸ìš°ëŸ¬, ê°€ë ¤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ê³µë¶€ë‘ ì‹¸ìš°ë‹¤ë‹ˆ</td>\n",
              "      <td>[ê³µë¶€, ë‘, ì‹¸ìš°ë‹¤ë‹ˆ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>ì¸ì •ìš”ã…‹ã…‹ã…‹</td>\n",
              "      <td>[ì¸ì •, ìš”]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4845 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                        comment_cut\n",
              "0     wm06nhjoAQ8  ...                           [ê°“, ì§íˆ, ë¼ë©´, ì€, ì§„, ìˆœì´, ì§€]\n",
              "1     wm06nhjoAQ8  ...                                    [ë‚˜, ë§Œ, ì¬ë°Œê²Œ, ë´¤ë‚˜]\n",
              "2     wm06nhjoAQ8  ...  [í•˜ë°˜, ë„ë³´, ê³ ë„, í—ˆë¬´í–ˆëŠ”ë°ì´ê²ƒë„, ê·¸ëŸ°, ê°€ìš”, ì‚´ì•„ë§Œ, ìˆë‹¤, ì¸ê°€ìš”, ì˜¤...\n",
              "3     wm06nhjoAQ8  ...  [ê·¸ëŸ°ë°, ì œ, ê°€ë³´ê¸°ì—”, ê´œì°®, ì€, ê²Œ, ìƒì¡´, ì˜, ìƒê°, ì„, ëª», í•˜ê³ , ...\n",
              "4     wm06nhjoAQ8  ...                                           [ë¶ˆí¸í•˜, ë„¹]\n",
              "...           ...  ...                                                ...\n",
              "4840  YzS9h3T2bXY  ...                           [ë‚˜, ë§Œ, ì´, ë…¸ë˜, ê°€, ë¦„, ë¼ì¹œê°€]\n",
              "4841  YzS9h3T2bXY  ...  [ì´, ê±°, ë“¤ìœ¼ë©´ì„œ, í•™ì›, ê°ˆ, ì¤€ë¹„, í•˜ë©´, ì™„ì „, ì¢€ë¹„, ë‘, ì‹¸ìš°ëŸ¬, ê°€ë ¤...\n",
              "4842  YzS9h3T2bXY  ...                                      [ê³µë¶€, ë‘, ì‹¸ìš°ë‹¤ë‹ˆ]\n",
              "4843  YzS9h3T2bXY  ...                                                 []\n",
              "4844  YzS9h3T2bXY  ...                                            [ì¸ì •, ìš”]\n",
              "\n",
              "[4845 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_5Pd7DIScCT"
      },
      "source": [
        "sent_dic = pd.read_csv('SentiWord_Dict.txt',sep = '\\t',header=None)\n",
        "sent_dic.iloc[14850,0]='ê°ˆë“±'\n",
        "\n",
        "pos_dic = sent_dic[sent_dic[1]>0]\n",
        "neg_dic = sent_dic[sent_dic[1]<0]\n",
        "neu_dic = sent_dic[sent_dic[1]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuC83E8qEE_r"
      },
      "source": [
        "# class ì„ ì–¸ìœ¼ë¡œ í•œë²ˆì— ì‘ì—… ì²˜ë¦¬\n",
        "\n",
        "class Aurora3:\n",
        "    \n",
        "    def __init__(self, df,sent_dic):\n",
        "        self.df = df\n",
        "        self.okt = konlpy.tag.Okt()\n",
        "        self.sent_dic = sent_dic\n",
        "        \n",
        "    def get_df(self):# ìµœì¢… ê²°ê³¼ ë°˜í™˜\n",
        "        #print(\"ë¬¸ì¥ í† í°í™” ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "        #self.tokenizer_run()\n",
        "        \n",
        "        print(\"ê°ì„±ì‚¬ì „ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "        self.expand_sent_dic()\n",
        "        \n",
        "        print(\"ë¬¸ì¥ ê°ì„±ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤....\")\n",
        "        self.sent_analyze()\n",
        "        return self.df\n",
        "    \"\"\"    \n",
        "    def tokenizer_run(self): # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ & í† í°í™”\n",
        "        tqdm.pandas()\n",
        "        \n",
        "        def text_preprocess(x): \n",
        "            text=[]\n",
        "            \n",
        "            x1 = re.sub(\"<.+?>\",\"\",x)\n",
        "            a = re.sub('[^ê°€-í£0-9a-zA-Z\\\\s]', '',x1)\n",
        "            for j in a.split():\n",
        "                text.append(j)\n",
        "            return ' '.join(text)\n",
        "\n",
        "        def tokenize(x):\n",
        "            text = []\n",
        "            tokens = self.okt.pos(x)\n",
        "            for token in tokens :\n",
        "                if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
        "                    text.append(token[0])\n",
        "            return text\n",
        "\n",
        "        self.df['comment_cut'] = self.df['sentence'].apply(lambda x : text_preprocess(x))\n",
        "        self.df['comment_cut'] = self.df['comment_cut'].progress_apply(lambda x: tokenize(x))\n",
        "    \"\"\"\n",
        "    def expand_sent_dic(self):\n",
        "        sent_dic = self.sent_dic\n",
        "        \n",
        "        def make_sent_dict(x) :\n",
        "            pos=[]\n",
        "            neg=[]\n",
        "            tmp={}\n",
        "\n",
        "            for sentence in tqdm(x):\n",
        "                for word in sentence :\n",
        "                    target = sent_dic[sent_dic[0]==word]\n",
        "                    if len(target)==1: # ê¸°ì¡´ì— ìˆëŠ” ë‹¨ì–´ë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "                        score = float(target[1])\n",
        "                        if score > 0:\n",
        "                            pos.append(word)\n",
        "                        elif score < 0:\n",
        "                            neg.append(word)                \n",
        "                    tmp[word] = {'W':0,'WP':0,'WN':0} # ê°ì„±ì‚¬ì „ êµ¬ì„±\n",
        "            pos = list(set(pos))\n",
        "            neg = list(set(neg))\n",
        "\n",
        "            for sentence in tqdm(x):\n",
        "                for word in sentence :\n",
        "                    tmp[word]['W'] += 1 # ë¹ˆë„ ìˆ˜\n",
        "                    for po in pos :\n",
        "                        if po in sentence:\n",
        "                            tmp[word]['WP'] += 1 # ê¸ì •ë‹¨ì–´ê³¼ ê°™ì€ ë¬¸ì¥ ë‚´ ë‹¨ì–´ì¼ ë•Œ\n",
        "                            break\n",
        "                    for ne in neg:\n",
        "                        if ne in sentence:\n",
        "                            tmp[word]['WN'] += 1 # ë¶€ì •ë‹¨ì–´ì™€ ê°™ì€ ë¬¸ì¥ë‚´ ë‹¨ì–´ì¼ ë•Œ\n",
        "                            break\n",
        "            return pos, neg, pd.DataFrame(tmp)\n",
        "        \n",
        "        def make_score_dict(d,p,n):\n",
        "            N=sum(d.iloc[0,::])\n",
        "            pos_cnt=sum(d.loc[::,p].iloc[0,::])\n",
        "            neg_cnt=sum(d.loc[::,n].iloc[0,::])\n",
        "\n",
        "            trans =d.T\n",
        "            trans['neg_cnt']=neg_cnt\n",
        "            trans['pos_cnt']=pos_cnt\n",
        "            trans['N']=N\n",
        "\n",
        "            trans['MI_P']=np.log2(trans['WP']*trans['N']/trans['W']*trans['pos_cnt'])\n",
        "            trans['MI_N']=np.log2(trans['WN']*trans['N']/trans['W']*trans['neg_cnt'])\n",
        "            trans['SO_MI']=trans['MI_P'] - trans['MI_N']\n",
        "\n",
        "            trans = trans.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
        "            trans = trans.sort_values(by=['SO_MI'],ascending=False)\n",
        "            return trans\n",
        "        \n",
        "        def update_dict(d):\n",
        "            add_Dic = {0:[],1:[]}\n",
        "            for i in d.T.items():\n",
        "                if i[0] not in list(sent_dic[0]):\n",
        "                    if len(i[0]) > 1:\n",
        "                        add_Dic[0].append(i[0])\n",
        "                        add_Dic[1].append(i[1]['SO_MI'])\n",
        "\n",
        "            add_Dic=pd.DataFrame(add_Dic)\n",
        "            Sentiment=pd.merge(sent_dic,add_Dic,'outer')\n",
        "            return Sentiment\n",
        "        \n",
        "        self.pos, self.neg, self.new_dict = make_sent_dict(self.df['comment_cut'].values)\n",
        "        \n",
        "        self.t_dict = make_score_dict(self.new_dict,self.pos,self.neg)\n",
        "        self.t_dict['SO_MI'] = scaler.fit_transform(self.t_dict['SO_MI'].values.reshape(-1,1))\n",
        "       \n",
        "        self.add_dict =update_dict(self.t_dict)\n",
        "    \n",
        "    def sent_analyze(self): # ë°ì´í„° ê°ì„±ë¶„ì„\n",
        "        tqdm.pandas()\n",
        "        \n",
        "        def get_cnt(x):\n",
        "            cnt = 0\n",
        "            for word in list(set(x)):\n",
        "                target = self.add_dict[self.add_dict[0]==word]\n",
        "                if len(target)==1:\n",
        "                    cnt += float(target[1])\n",
        "            return cnt\n",
        "\n",
        "        def get_ratio(x): # logë¡œ score ì •ê·œí™”\n",
        "            score = x['score']\n",
        "            length = np.log10(len(x['comment_cut']))+1\n",
        "            try:\n",
        "                ratio= round(score/length,2)\n",
        "            except:\n",
        "                ratio = 0\n",
        "            return ratio\n",
        "        \n",
        "        tqdm.pandas()\n",
        "        self.df['score']= self.df['comment_cut'].progress_apply(lambda x : get_cnt(x))\n",
        "        self.df['ratio'] = self.df.apply(lambda x: get_ratio(x), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTuvUW1RSP_T"
      },
      "source": [
        "# ê°ì„±ë¶„ì„ ì ìˆ˜ ë„ì¶œ\n",
        "\n",
        "test = Aurora3(df,sent_dic)\n",
        "res = test.get_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebzpTxXEE_v"
      },
      "source": [
        "# score ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥\n",
        "\n",
        "score_res = pd.DataFrame(res)\n",
        "score_res.to_csv(f\"/content/drive/MyDrive/íŒŒì¼ê²½ë¡œ/score_youtube_comments_{movie_name}.csv\", header=True, index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}